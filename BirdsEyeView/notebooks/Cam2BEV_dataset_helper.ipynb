{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63d842d3",
   "metadata": {},
   "source": [
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "591e28a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "sys.path.append('/home/surya/Downloads/cam2bev-data-master-2_F/')\n",
    "from utils import load_image, one_hot_encode_image, parse_convert_xml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb895d3e",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63ce4fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_NUM_TO_KEEP = 8000\n",
    "VAL_NUM_TO_KEEP = 1500\n",
    "# DATA_ROOT_DIR = '/home/surya/Downloads/cam2bev-data-master/1_FRLR'\n",
    "DATA_ROOT_DIR = '/home/surya/Downloads/cam2bev-data-master-2_F/2_F'\n",
    "TRAIN_DIR = os.path.join(DATA_ROOT_DIR, *['train'])\n",
    "VAL_DIR = os.path.join(DATA_ROOT_DIR, *['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bdb4237",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPalette = [\n",
    "    [np.array([128,  64, 128])],                                                       # road  \n",
    "    [np.array([244,  35, 232]), np.array([250, 170, 160])],                            # sidewalk\n",
    "    [np.array([255,   0,   0])],                                                       # person   \n",
    "    [np.array([  0,   0, 142]), np.array([  0,   0, 110])],                            # car\n",
    "    [np.array([ 0,  0, 70])],                                                          # Truck\n",
    "    [np.array([  0,  60, 100]), np.array([ 0,  0, 90])],                               # Bus\n",
    "    [np.array([220,  20,  60]), np.array([  0,   0, 230]), np.array([119,  11,  32])], # Two-wheelers\n",
    "    [np.array([0, 0, 0]), np.array([111,  74,   0]), np.array([81,  0, 81]),           # static obstacles\n",
    "    np.array([230, 150, 140]), np.array([70, 70, 70]), np.array([102, 102, 156]),      \n",
    "    np.array([190, 153, 153]), np.array([180, 165, 180]), np.array([150, 100, 100]),   \n",
    "    np.array([150, 120,  90]), np.array([153, 153, 153]), np.array([153, 153, 153]),\n",
    "    np.array([250, 170,  30]), np.array([220, 220,   0]), np.array([  0,  80, 100])],\n",
    "    [np.array([107, 142,  35]), np.array([152, 251, 152])],                            # Vegetation\n",
    "    [np.array([ 70, 130, 180])]                                                        # Sky\n",
    "]\n",
    "\n",
    "\n",
    "# Sky is added to Static obstacles and Occlusion is added as 10th class\n",
    "FLRR_outputPalette = [\n",
    "    [np.array([128,  64, 128])],\n",
    "    [np.array([244,  35, 232]), np.array([250, 170, 160])],\n",
    "    [np.array([255,   0,   0])],\n",
    "    [np.array([  0,   0, 142]), np.array([  0,   0, 110])],\n",
    "    [np.array([ 0,  0, 70])],\n",
    "    [np.array([  0,  60, 100]), np.array([ 0,  0, 90])],\n",
    "    [np.array([220,  20,  60]), np.array([  0,   0, 230]), np.array([119,  11,  32])],\n",
    "    [np.array([0, 0, 0]), np.array([111,  74,   0]), np.array([81,  0, 81]),\n",
    "     np.array([230, 150, 140]), np.array([70, 70, 70]), np.array([102, 102, 156]),\n",
    "     np.array([190, 153, 153]), np.array([180, 165, 180]), np.array([150, 100, 100]),\n",
    "     np.array([150, 120,  90]), np.array([153, 153, 153]), np.array([153, 153, 153]),\n",
    "     np.array([250, 170,  30]), np.array([220, 220,   0]), np.array([  0,  80, 100]), np.array([ 70, 130, 180])],\n",
    "    [np.array([107, 142,  35]), np.array([152, 251, 152])], \n",
    "    [np.array([150, 150, 150])]              # OCCLUSION CLASS\n",
    "]\n",
    "\n",
    "F_outputPallete = [\n",
    "            [np.array([128,  64, 128])],\n",
    "            [np.array([  0,   0, 142]), np.array([  0,   0, 110]), np.array([ 0,  0, 70]),\n",
    "             np.array([  0,  60, 100]), np.array([ 0,  0, 90]), np.array([220,  20,  60]),\n",
    "             np.array([  0,   0, 230]), np.array([119,  11,  32])],\n",
    "            [np.array([0, 0, 0]), np.array([255,   0,   0]), np.array([244,  35, 232]),\n",
    "             np.array([250, 170, 160]), np.array([111,  74,   0]), np.array([81,  0, 81]),\n",
    "             np.array([230, 150, 140]), np.array([70, 70, 70]), np.array([102, 102, 156]),\n",
    "             np.array([190, 153, 153]), np.array([180, 165, 180]), np.array([150, 100, 100]),\n",
    "             np.array([150, 120,  90]), np.array([153, 153, 153]), np.array([153, 153, 153]),\n",
    "             np.array([250, 170,  30]), np.array([220, 220,   0]), np.array([  0,  80, 100]),\n",
    "             np.array([107, 142,  35]), np.array([152, 251, 152]), np.array([ 70, 130, 180])],\n",
    "            [np.array([150, 150, 150])]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5efa646",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22729047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFilesInDir(directory):\n",
    "    return sorted(os.listdir(directory))\n",
    "\n",
    "def fileNamesWithoutExtension(files):\n",
    "    return [x.split('.')[-2] for x in files]\n",
    "\n",
    "def checkFoldersContainSameFiles(folders):\n",
    "    assert len(folders) > 0\n",
    "    refFiles = getFilesInDir(folders[0])\n",
    "    refFilesWithoutExt = set(fileNamesWithoutExtension(refFiles))\n",
    "    numRefFiles = len(refFiles)\n",
    "    \n",
    "    filesMatch = True\n",
    "    for folder in folders[1:]:\n",
    "        files = getFilesInDir(folder)\n",
    "        if (len(files) == numRefFiles):\n",
    "            filesWithoutExt = set(fileNamesWithoutExtension(files))\n",
    "            if(len(filesWithoutExt - refFilesWithoutExt) == 0):\n",
    "                continue\n",
    "            else:\n",
    "                filesMatch = False\n",
    "                print(f\"{folder} file names mismatch\")\n",
    "                break\n",
    "        else:\n",
    "            filesMatch = False\n",
    "            print(f\"{folder} contains {len(files)} files, while numRefFiles = {numRefFiles}\")\n",
    "            break\n",
    "            \n",
    "    return filesMatch\n",
    "\n",
    "def getRandomIndices(size, numToKeep):\n",
    "    indices = np.random.choice(size, size=numToKeep, replace=False)\n",
    "    return indices\n",
    "\n",
    "def filterListByIndices(data, indices):\n",
    "    return [data[i] for i in indices]\n",
    "\n",
    "def deleteFile(filePath):\n",
    "    if os.path.exists(filePath):\n",
    "        os.remove(filePath)\n",
    "\n",
    "def getLastIndices(size, numToKeep):\n",
    "    return np.arange(size - numToKeep, size)\n",
    "\n",
    "def getLastIndices(size, numToDelete):\n",
    "    return np.arange(size - numToDelete, size)\n",
    "\n",
    "def reduceDataset(inputDir, numberToKeep, reduceType='random'):\n",
    "    DATASET_FOLDERS = [os.path.join(inputDir,x) for x in os.listdir(inputDir) \\\n",
    "                            if os.path.isdir(os.path.join(inputDir,x))]\n",
    "\n",
    "    refFiles = getFilesInDir(DATASET_FOLDERS[0])\n",
    "    numRefFiles = len(refFiles)\n",
    "\n",
    "    # randomly choose indices to delete\n",
    "    if reduceType == 'random':\n",
    "        indicesToDelete = getRandomIndices(numRefFiles, numRefFiles - numberToKeep)\n",
    "    else:\n",
    "        indicesToDelete = getLastIndices(numRefFiles, numRefFiles - numberToKeep)\n",
    "        \n",
    "    filesToBeDeteled = filterListByIndices(refFiles, indicesToDelete)\n",
    "\n",
    "    # delete extra files\n",
    "    for folder in DATASET_FOLDERS:\n",
    "        print(folder)\n",
    "        for file in tqdm(filesToBeDeteled):\n",
    "            absFilePath = os.path.join(folder, file)\n",
    "            deleteFile(absFilePath)\n",
    "\n",
    "    # check folders for files\n",
    "    checkFoldersContainSameFiles(DATASET_FOLDERS)        \n",
    "    \n",
    "\n",
    "def resizeDataset(inputDir, newWidth, newHeight):\n",
    "    DATASET_FOLDERS = [os.path.join(inputDir,x) for x in os.listdir(inputDir) \\\n",
    "                            if os.path.isdir(os.path.join(inputDir,x))]\n",
    "\n",
    "    for folder in DATASET_FOLDERS:\n",
    "        print(folder)\n",
    "        filesInDir = getFilesInDir(folder)\n",
    "        for file in tqdm(filesInDir):\n",
    "            absFilePath = os.path.join(folder, file)\n",
    "            image = cv2.imread(absFilePath)\n",
    "            image = cv2.resize(image, (newWidth, newHeight), interpolation=cv2.INTER_CUBIC)\n",
    "            cv2.imwrite(absFilePath, image)\n",
    "            \n",
    "def replaceWithOhEncoding(inputDir, labelDir, inputColorMap, outputColorMap):\n",
    "    DATASET_FOLDERS = [os.path.join(inputDir,x) for x in os.listdir(inputDir) \\\n",
    "                            if os.path.isdir(os.path.join(inputDir,x))]\n",
    "\n",
    "    for folder in DATASET_FOLDERS:\n",
    "        print(folder)\n",
    "        if(labelDir in folder):\n",
    "            colorMap = outputColorMap\n",
    "            print('outputColorMap')\n",
    "        else:\n",
    "            colorMap = inputColorMap\n",
    "            print('inputColorMap')\n",
    "        \n",
    "        filesInDir = getFilesInDir(folder)\n",
    "        for file in tqdm(filesInDir):\n",
    "            absFilePath = os.path.join(folder, file)\n",
    "            image = load_image(absFilePath)\n",
    "            image = one_hot_encode_image(image, colorMap).astype(np.bool_)\n",
    "            np.save(absFilePath.replace('png', 'npy'), image)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7de6a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/surya/Downloads/cam2bev-data-master-2_F/2_F/val/front\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1672/1672 [00:00<00:00, 13584.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/surya/Downloads/cam2bev-data-master-2_F/2_F/val/bev+occlusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1672/1672 [00:00<00:00, 17808.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# reduceDataset(TRAIN_DIR, numberToKeep=TRAIN_NUM_TO_KEEP)\n",
    "reduceDataset(VAL_DIR, numberToKeep=VAL_NUM_TO_KEEP, reduceType='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f91784",
   "metadata": {},
   "outputs": [],
   "source": [
    "resizeDataset(TRAIN_DIR, newWidth=512, newHeight=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa22aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "resizeDataset(VAL_DIR, newWidth=512, newHeight=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbb78e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceWithOhEncoding(TRAIN_DIR, labelDir='bev+occlusion', \n",
    "                      inputColorMap=inputPalette, outputColorMap=F_outputPallete)\n",
    "replaceWithOhEncoding(VAL_DIR, labelDir='bev+occlusion',\n",
    "                      inputColorMap=inputPalette, outputColorMap=F_outputPallete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fac3e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_distribution(folder, palette, shape=(256, 512)):\n",
    "    # get filepaths\n",
    "    files = [os.path.join(folder, f) for f in os.listdir(folder) if not f.startswith(\".\")]\n",
    "    n_classes = len(palette)\n",
    "\n",
    "    px = shape[0] * shape[1]\n",
    "    distribution = {}\n",
    "    for k in range(n_classes):\n",
    "        distribution[str(k)] = 0\n",
    "\n",
    "    i = 0\n",
    "    bar = tqdm(files)\n",
    "    for f in bar:\n",
    "        img = np.load(f)\n",
    "        classes = np.argmax(img, axis=0)\n",
    "        unique, counts = np.unique(classes, return_counts=True)\n",
    "        occs = dict(zip(unique, counts))\n",
    "        \n",
    "        for k in range(n_classes):\n",
    "            occ = occs[k] if k in occs.keys() else 0\n",
    "            distribution[str(k)] = (distribution[str(k)] * i + occ / px) / (i+1)\n",
    "\n",
    "        bar.set_postfix(distribution)\n",
    "        i += 1\n",
    "    return distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063710cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dist = get_class_distribution(os.path.join(TRAIN_DIR, *['bev+occlusion']), outputPalette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b46b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e4c8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True, precision=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb64825",
   "metadata": {},
   "outputs": [],
   "source": [
    "classCounts = np.array(list(class_dist.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16404d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classCounts * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad6b53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(classCounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d21f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 / classCounts)/ np.sum(1 / classCounts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
