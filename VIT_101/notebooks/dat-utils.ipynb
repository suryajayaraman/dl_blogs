{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28ed36db-3d68-48c0-9d4f-bffa4b51b4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# checkpoint = torch.load('/home/surya/Downloads/fpn_dat_t_80k.pth')\n",
    "checkpoint = torch.load('/home/surya/Downloads/mrcn_dat_t_1x.pth')\n",
    "\n",
    "from collections import OrderedDict\n",
    "new_state_dict = OrderedDict()\n",
    "\n",
    "for k,v in checkpoint['state_dict'].items():\n",
    "    if('backbone' in k):\n",
    "        if(k.startswith(\"backbone.norms.\")):\n",
    "            pass\n",
    "        else:\n",
    "            new_key = k.replace(\"backbone.\", \"\")\n",
    "            new_state_dict[new_key] = v\n",
    "torch.save(new_state_dict, '/home/surya/Downloads/mrcn_dat_t_backbone.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9dd08d2-fc58-4c99-a803-c4916a98f1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['cls_norm.norm.weight', 'cls_norm.norm.bias', 'cls_head.weight', 'cls_head.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# load pretrained model\n",
    "checkpoint = torch.load('/home/surya/Downloads/mrcn_dat_t_backbone.pth')\n",
    "\n",
    "from dat import DAT\n",
    "model = DAT()\n",
    "model.eval();\n",
    "model.to(device);\n",
    "model.load_state_dict(checkpoint, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31e62d49-0a7e-4057-ac09-a9f2fbaa6460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cls_head.bias',\n",
       " 'cls_head.weight',\n",
       " 'cls_norm.norm.bias',\n",
       " 'cls_norm.norm.weight'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_state_dict_keyset = set(new_state_dict.keys())\n",
    "model_state_dict_keyset = set(model.state_dict().keys())\n",
    "model_state_dict_keyset.difference(new_state_dict_keyset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b3bbb3-c1f3-4f8d-ade8-ee42d236484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.sum(last_stage_attention))\n",
    "# print(torch.sum(last_stage_attention, dim=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a87cfe-f0f9-4e44-a58d-ebc8bf2f7cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, attn_i in enumerate(output_attns):\n",
    "#     top_scores, _ = torch.sort(attn_i.flatten(), descending=True)\n",
    "#     print(i, f\"{top_scores}\") #  : .4f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25020813-35ce-49cd-aa9d-674e39319bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_cumulative_attention(attentions):    \n",
    "#     cumulative_attentions = []\n",
    "#     if len(attentions) > 0:\n",
    "#         def process_attention(attn):\n",
    "#             nheads, npatches, _ = attn.shape\n",
    "#             normalized_attn = F.softmax(attn.sum(dim =0), dim=1)\n",
    "#             h = int(npatches **0.5)\n",
    "#             normalized_attn = normalized_attn.reshape(h, h, -1)\n",
    "#             return normalized_attn\n",
    "\n",
    "#         def scale_attention(attn, feat_size, nheads):\n",
    "#             attn = attn.unsqueeze(0)\n",
    "#             if((attn.shape[0] == feat_size) and (attn.shape[1] == feat_size)):\n",
    "#                 scaled_attn = attn\n",
    "#             else:\n",
    "#                 attn = einops.rearrange(attn, 'bs h w k -> bs k h w')\n",
    "#                 scaled_attn = F.interpolate(attn, (feat_size, feat_size), \n",
    "#                                           mode='bilinear', align_corners=True)\n",
    "#             scaled_attn = einops.rearrange(scaled_attn, 'bs k h w -> bs (h w) k')\n",
    "#             scaled_attn = scaled_attn.expand(nheads, -1, -1)\n",
    "#             return scaled_attn\n",
    "\n",
    "#         # start from last stage\n",
    "#         cumulative_attentions.append(attentions[-1])\n",
    "#         for i in range(1, len(attentions)):\n",
    "#             prev_attn = cumulative_attentions[-1]\n",
    "#             prev_attn = process_attention(prev_attn)\n",
    "            \n",
    "#             current_attn = attentions[len(attentions) - i - 1]\n",
    "#             nheads, npatches, _ = current_attn.shape\n",
    "#             curr_feat_size = int(npatches ** 0.5)\n",
    "#             scaled_prev_attn = scale_attention(prev_attn, curr_feat_size, nheads)\n",
    "#             current_attn = current_attn * scaled_prev_attn\n",
    "#             current_attn = F.softmax(current_attn, dim=2)\n",
    "#             cumulative_attentions.append(current_attn)\n",
    "\n",
    "#     # we stored in reverse order\n",
    "#     cumulative_attentions = cumulative_attentions[::-1]\n",
    "#     return cumulative_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f609c5c0-01cd-40f1-aa0d-a957d71a09a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumulative_attn = calculate_cumulative_attention(output_attns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1bd96b-b999-4221-a05b-2655d2c68e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, attn_i in enumerate(cumulative_attn):\n",
    "#     top_scores, _ = torch.sort(attn_i.flatten(), descending=True)\n",
    "#     print(i, f\"{top_scores}\") #  : .4f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a39229a-1f4a-4001-aeb7-b2e450d96b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take current attention map = [nh_o np_o 49]\n",
    "# interpolate pre attn map to current resolution = [np_o 49]\n",
    "# repeat scaled map to nh_o = [nh_o np_o 49]\n",
    "# apply softmax across 49 = [nh_o np_o 49]\n",
    "# set current stage to previous_stage            \n",
    "\n",
    "# prev stage attention = [nh, np, 49]\n",
    "# sum across heads = [np, 49]\n",
    "# normalize against 49 = [np, 49]\n",
    "# reshape to height, width = [hi wi 49]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(dat)",
   "language": "python",
   "name": "dat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
