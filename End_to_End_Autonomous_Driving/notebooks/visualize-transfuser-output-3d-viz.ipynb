{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bea7ccbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T10:50:10.157420Z",
     "iopub.status.busy": "2024-07-28T10:50:10.157031Z",
     "iopub.status.idle": "2024-07-28T10:51:56.973274Z",
     "shell.execute_reply": "2024-07-28T10:51:56.972021Z"
    },
    "papermill": {
     "duration": 106.827084,
     "end_time": "2024-07-28T10:51:56.975945",
     "exception": false,
     "start_time": "2024-07-28T10:50:10.148861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu\r\n",
      "Collecting torch==1.11.0+cpu\r\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-1.11.0%2Bcpu-cp310-cp310-linux_x86_64.whl (169.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.2/169.2 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting torchvision==0.12.0+cpu\r\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.12.0%2Bcpu-cp310-cp310-linux_x86_64.whl (14.7 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==1.11.0+cpu) (4.9.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision==0.12.0+cpu) (1.26.4)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision==0.12.0+cpu) (2.31.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.12.0+cpu) (9.5.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.12.0+cpu) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.12.0+cpu) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.12.0+cpu) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.12.0+cpu) (2024.2.2)\r\n",
      "Installing collected packages: torch, torchvision\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.1.2+cpu\r\n",
      "    Uninstalling torch-2.1.2+cpu:\r\n",
      "      Successfully uninstalled torch-2.1.2+cpu\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.16.2+cpu\r\n",
      "    Uninstalling torchvision-0.16.2+cpu:\r\n",
      "      Successfully uninstalled torchvision-0.16.2+cpu\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "pytorch-lightning 2.2.2 requires torch>=1.13.0, but you have torch 1.11.0+cpu which is incompatible.\r\n",
      "stable-baselines3 2.1.0 requires torch>=1.13, but you have torch 1.11.0+cpu which is incompatible.\r\n",
      "torchaudio 2.1.2+cpu requires torch==2.1.2, but you have torch 1.11.0+cpu which is incompatible.\r\n",
      "torchdata 0.7.1 requires torch>=2, but you have torch 1.11.0+cpu which is incompatible.\r\n",
      "torchtext 0.16.2+cpu requires torch==2.1.2, but you have torch 1.11.0+cpu which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed torch-1.11.0+cpu torchvision-0.12.0+cpu\r\n",
      "Looking in links: https://download.openmmlab.com/mmcv/dist/cpu/torch1.11/index.html\r\n",
      "Collecting mmcv-full==1.5.3\r\n",
      "  Downloading https://download.openmmlab.com/mmcv/dist/cpu/torch1.11.0/mmcv_full-1.5.3-cp310-cp310-manylinux1_x86_64.whl (21.7 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.7/21.7 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting addict (from mmcv-full==1.5.3)\r\n",
      "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mmcv-full==1.5.3) (1.26.4)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from mmcv-full==1.5.3) (21.3)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from mmcv-full==1.5.3) (9.5.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from mmcv-full==1.5.3) (6.0.1)\r\n",
      "Requirement already satisfied: yapf in /opt/conda/lib/python3.10/site-packages (from mmcv-full==1.5.3) (0.40.2)\r\n",
      "Requirement already satisfied: opencv-python>=3 in /opt/conda/lib/python3.10/site-packages (from mmcv-full==1.5.3) (4.9.0.80)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->mmcv-full==1.5.3) (3.1.1)\r\n",
      "Requirement already satisfied: importlib-metadata>=6.6.0 in /opt/conda/lib/python3.10/site-packages (from yapf->mmcv-full==1.5.3) (6.11.0)\r\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmcv-full==1.5.3) (4.2.0)\r\n",
      "Requirement already satisfied: tomli>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmcv-full==1.5.3) (2.0.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=6.6.0->yapf->mmcv-full==1.5.3) (3.17.0)\r\n",
      "Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\r\n",
      "Installing collected packages: addict, mmcv-full\r\n",
      "Successfully installed addict-2.4.0 mmcv-full-1.5.3\r\n",
      "Looking in links: https://download.openmmlab.com/mmdet/dist/cpu/torch1.11/index.html\r\n",
      "Collecting mmdet==2.25.0\r\n",
      "  Downloading mmdet-2.25.0-py3-none-any.whl.metadata (20 kB)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mmdet==2.25.0) (3.7.5)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mmdet==2.25.0) (1.26.4)\r\n",
      "Collecting pycocotools (from mmdet==2.25.0)\r\n",
      "  Downloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from mmdet==2.25.0) (1.16.0)\r\n",
      "Collecting terminaltables (from mmdet==2.25.0)\r\n",
      "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl.metadata (3.5 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmdet==2.25.0) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmdet==2.25.0) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmdet==2.25.0) (4.47.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmdet==2.25.0) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmdet==2.25.0) (21.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmdet==2.25.0) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmdet==2.25.0) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmdet==2.25.0) (2.9.0.post0)\r\n",
      "Downloading mmdet-2.25.0-py3-none-any.whl (1.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.8/427.8 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\r\n",
      "Installing collected packages: terminaltables, pycocotools, mmdet\r\n",
      "Successfully installed mmdet-2.25.0 pycocotools-2.0.8 terminaltables-3.1.10\r\n",
      "Collecting kaleido\r\n",
      "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl.metadata (15 kB)\r\n",
      "Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: kaleido\r\n",
      "Successfully installed kaleido-0.2.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.11.0+cpu torchvision==0.12.0+cpu --extra-index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install mmcv-full==1.5.3 -f https://download.openmmlab.com/mmcv/dist/cpu/torch1.11/index.html\n",
    "!pip install mmdet==2.25.0 -f https://download.openmmlab.com/mmdet/dist/cpu/torch1.11/index.html\n",
    "!pip install kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34b5d0e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T10:51:57.030944Z",
     "iopub.status.busy": "2024-07-28T10:51:57.030551Z",
     "iopub.status.idle": "2024-07-28T10:51:57.969408Z",
     "shell.execute_reply": "2024-07-28T10:51:57.968221Z"
    },
    "papermill": {
     "duration": 0.969583,
     "end_time": "2024-07-28T10:51:57.972134",
     "exception": false,
     "start_time": "2024-07-28T10:51:57.002551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import random\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(suppress=True, precision=5)\n",
    "sys.path.append('/kaggle/input/transfuser-e2e-scripts')\n",
    "\n",
    "# dl imports\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b3e203",
   "metadata": {
    "papermill": {
     "duration": 0.026857,
     "end_time": "2024-07-28T10:51:58.025404",
     "exception": false,
     "start_time": "2024-07-28T10:51:57.998547",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CARLA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64e59cec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T10:51:58.081784Z",
     "iopub.status.busy": "2024-07-28T10:51:58.081224Z",
     "iopub.status.idle": "2024-07-28T10:51:58.707959Z",
     "shell.execute_reply": "2024-07-28T10:51:58.706668Z"
    },
    "papermill": {
     "duration": 0.657281,
     "end_time": "2024-07-28T10:51:58.710789",
     "exception": false,
     "start_time": "2024-07-28T10:51:58.053508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 30.56it/s]\n",
      "There are 95 samples in Demo dataset\n"
     ]
    }
   ],
   "source": [
    "from config import GlobalConfig\n",
    "from data import CARLA_Data\n",
    "\n",
    "root_dir = '/kaggle/input/carla-e2e-data/demo/scenario1/'\n",
    "config = GlobalConfig()\n",
    "config.pred_len = 7\n",
    "demo_set = CARLA_Data(root=root_dir, config=config, routeKey='route0', load_raw_lidar=True)\n",
    "print(f\"There are {len(demo_set)} samples in Demo dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a346a550",
   "metadata": {
    "papermill": {
     "duration": 0.026671,
     "end_time": "2024-07-28T10:51:58.766767",
     "exception": false,
     "start_time": "2024-07-28T10:51:58.740096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Create pytorch style dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d20f55a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T10:51:58.822874Z",
     "iopub.status.busy": "2024-07-28T10:51:58.822297Z",
     "iopub.status.idle": "2024-07-28T10:51:58.828466Z",
     "shell.execute_reply": "2024-07-28T10:51:58.827353Z"
    },
    "papermill": {
     "duration": 0.037469,
     "end_time": "2024-07-28T10:51:58.831296",
     "exception": false,
     "start_time": "2024-07-28T10:51:58.793827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataloader_demo = DataLoader(demo_set, shuffle=False, batch_size=2, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeca8c6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T10:51:58.894438Z",
     "iopub.status.busy": "2024-07-28T10:51:58.893428Z",
     "iopub.status.idle": "2024-07-28T10:51:59.809392Z",
     "shell.execute_reply": "2024-07-28T10:51:59.807777Z"
    },
    "papermill": {
     "duration": 0.950403,
     "end_time": "2024-07-28T10:51:59.811779",
     "exception": false,
     "start_time": "2024-07-28T10:51:58.861376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample data is of type <class 'dict'> and has following keys\n",
      "rgb [2, 3, 160, 704]\n",
      "bev [2, 160, 160]\n",
      "depth [2, 160, 704]\n",
      "semantic [2, 160, 704]\n",
      "speed [2]\n",
      "x_command [2]\n",
      "y_command [2]\n",
      "target_point [2, 2]\n",
      "target_point_image [2, 1, 256, 256]\n",
      "raw_lidar [2, 10000, 3]\n",
      "num_raw_lidar_points [2]\n",
      "lidar [2, 2, 256, 256]\n",
      "label [2, 20, 7]\n",
      "ego_waypoint [2, 7, 2]\n"
     ]
    }
   ],
   "source": [
    "sample_data = next(iter(dataloader_demo))\n",
    "print(f\"sample data is of type {type(sample_data)} and has following keys\")\n",
    "\n",
    "for k,v in sample_data.items():\n",
    "    print(k, list(v.shape))\n",
    "    \n",
    "del sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109c644b",
   "metadata": {
    "papermill": {
     "duration": 0.025892,
     "end_time": "2024-07-28T10:51:59.864219",
     "exception": false,
     "start_time": "2024-07-28T10:51:59.838327",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "098a6288",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T10:51:59.918951Z",
     "iopub.status.busy": "2024-07-28T10:51:59.918541Z",
     "iopub.status.idle": "2024-07-28T10:52:21.569253Z",
     "shell.execute_reply": "2024-07-28T10:52:21.568156Z"
    },
    "papermill": {
     "duration": 21.681197,
     "end_time": "2024-07-28T10:52:21.571580",
     "exception": false,
     "start_time": "2024-07-28T10:51:59.890383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd9600a470d4e39a8cedcc8329dc154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/78.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "from model import LidarCenterNet\n",
    "model = LidarCenterNet(config, device, config.backbone, image_architecture='regnety_032', \n",
    "                           lidar_architecture='regnety_032', estimate_loss = False)\n",
    "model.to(device);\n",
    "model.config.debug = True\n",
    "\n",
    "model.eval();\n",
    "checkpt = torch.load('/kaggle/input/carla-transfuser-regnet032/transfuser_regnet032_seed1_39.pth', map_location=device)\n",
    "model.load_state_dict(checkpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df8fbd6",
   "metadata": {
    "papermill": {
     "duration": 0.027356,
     "end_time": "2024-07-28T10:52:21.626423",
     "exception": false,
     "start_time": "2024-07-28T10:52:21.599067",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57c70466",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T10:52:21.683004Z",
     "iopub.status.busy": "2024-07-28T10:52:21.682614Z",
     "iopub.status.idle": "2024-07-28T10:52:21.690191Z",
     "shell.execute_reply": "2024-07-28T10:52:21.689206Z"
    },
    "papermill": {
     "duration": 0.037794,
     "end_time": "2024-07-28T10:52:21.692396",
     "exception": false,
     "start_time": "2024-07-28T10:52:21.654602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import VEHICLE_TO_LIDAR_FWD, LIDAR_HEIGHT\n",
    "\n",
    "def generate_lane_points(waypoints, lane_width = 1.0):\n",
    "    # input waypoints are 2d coordinates of centerline (N,2)\n",
    "    # this function generates left and right lane corners\n",
    "    # by subtracting and adding half lane width. We convert\n",
    "    # to 3D Lidar coordinates by placing points at ground level\n",
    "\n",
    "    n_points = waypoints.shape[0]\n",
    "    lane_points = np.zeros((n_points * 2 , 3))\n",
    "    \n",
    "    # vehicle to lidar frame\n",
    "    lane_points[:n_points, 0] = waypoints[:,0] + VEHICLE_TO_LIDAR_FWD\n",
    "    lane_points[n_points:, 0] = waypoints[:,0] + VEHICLE_TO_LIDAR_FWD\n",
    "    \n",
    "    # left and right lanes\n",
    "    lane_points[:n_points,1] = waypoints[:,1] - (lane_width * 0.5)\n",
    "    lane_points[n_points:,1] = waypoints[:,1] + (lane_width * 0.5)\n",
    "    \n",
    "    # fixed height\n",
    "    lane_points[:,2] = -LIDAR_HEIGHT\n",
    "    return lane_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f97d63e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T10:52:21.749337Z",
     "iopub.status.busy": "2024-07-28T10:52:21.748926Z",
     "iopub.status.idle": "2024-07-28T10:52:21.757578Z",
     "shell.execute_reply": "2024-07-28T10:52:21.756468Z"
    },
    "papermill": {
     "duration": 0.040738,
     "end_time": "2024-07-28T10:52:21.760335",
     "exception": false,
     "start_time": "2024-07-28T10:52:21.719597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bev_to_lidar = np.array([\n",
    "            [0, -(1/8.0), 32],\n",
    "            [-(1/8.0), 0, 16],\n",
    "            [0 , 0, 1]\n",
    "])\n",
    "\n",
    "\n",
    "def convert_to_3d_bboxes(boxes_2d):\n",
    "    n_boxes = boxes_2d.shape[0]\n",
    "    bbox_3d = np.zeros((n_boxes, 7))\n",
    "\n",
    "    # xy position from bev pixels to metres\n",
    "    homogenous_coordinates = np.hstack([boxes_2d[:, :2], np.ones((n_boxes, 1))])\n",
    "    bbox_3d[:, :2] = (bev_to_lidar @ homogenous_coordinates.T).T[:, :2]\n",
    "    bbox_3d[:, 3] = boxes_2d[:, 3] / 8  # length \n",
    "    bbox_3d[:, 4] = boxes_2d[:, 2] / 8  # width\n",
    "    bbox_3d[:, 6] = -boxes_2d[:, 4]      # yaw\n",
    "\n",
    "    # hardcoding z values\n",
    "    bbox_3d[:, 2] = -1.25\n",
    "    bbox_3d[:, 5] = 2.5\n",
    "    return bbox_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4bdb86f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T10:52:21.815509Z",
     "iopub.status.busy": "2024-07-28T10:52:21.815084Z",
     "iopub.status.idle": "2024-07-28T10:52:21.822795Z",
     "shell.execute_reply": "2024-07-28T10:52:21.821616Z"
    },
    "papermill": {
     "duration": 0.038007,
     "end_time": "2024-07-28T10:52:21.825034",
     "exception": false,
     "start_time": "2024-07-28T10:52:21.787027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_rotated_bbox(bbox):\n",
    "    x, y, w, h, yaw, _, _  =  bbox\n",
    "\n",
    "    bbox = np.array([[h,   w, 1],\n",
    "                     [h,  -w, 1],\n",
    "                     [-h, -w, 1],\n",
    "                     [-h,  w, 1],\n",
    "                ])\n",
    "    \n",
    "    # The height and width of the bounding box value was changed by this factor \n",
    "    # during data collection. Fix that for future datasets and remove    \n",
    "    bbox[:, :2] /= 2\n",
    "    bbox[:, :2] = bbox[:, [1, 0]]\n",
    "\n",
    "    c, s = np.cos(yaw), np.sin(yaw)\n",
    "    # use y x because coordinate is changed\n",
    "    r1_to_world = np.array([[c, -s, x], [s, c, y], [0, 0, 1]])\n",
    "    bbox = r1_to_world @ bbox.T\n",
    "    bbox = bbox.T\n",
    "    bbox = np.clip(bbox, 0, 256)\n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0141525",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T10:52:21.881906Z",
     "iopub.status.busy": "2024-07-28T10:52:21.881537Z",
     "iopub.status.idle": "2024-07-28T10:52:21.890334Z",
     "shell.execute_reply": "2024-07-28T10:52:21.889333Z"
    },
    "papermill": {
     "duration": 0.040305,
     "end_time": "2024-07-28T10:52:21.892613",
     "exception": false,
     "start_time": "2024-07-28T10:52:21.852308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_scatter_plot(x,y, mode='lines', marker_size=2, color=None, **kwargs):\n",
    "    return go.Scatter(x=x, y=y, mode=mode, hoverinfo='skip',showlegend=False, \n",
    "                        marker = dict(size=marker_size, color=color), **kwargs)\n",
    "\n",
    "def plot_box_corners2d(box2d, color,**kwargs):\n",
    "    return [\n",
    "        get_scatter_plot([box2d[0,0], box2d[1,0]], [box2d[0,1], box2d[1,1]], color=color, **kwargs),\n",
    "        get_scatter_plot([box2d[1,0], box2d[2,0]], [box2d[1,1], box2d[2,1]], color=color, **kwargs),\n",
    "        get_scatter_plot([box2d[2,0], box2d[3,0]], [box2d[2,1], box2d[3,1]], color=color, **kwargs),\n",
    "        get_scatter_plot([box2d[3,0], box2d[0,0]], [box2d[3,1], box2d[0,1]], color=color, **kwargs),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139afa07",
   "metadata": {
    "papermill": {
     "duration": 0.026627,
     "end_time": "2024-07-28T10:52:21.946609",
     "exception": false,
     "start_time": "2024-07-28T10:52:21.919982",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Visualization class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da498216",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T10:52:22.002723Z",
     "iopub.status.busy": "2024-07-28T10:52:22.002360Z",
     "iopub.status.idle": "2024-07-28T10:52:22.008602Z",
     "shell.execute_reply": "2024-07-28T10:52:22.007373Z"
    },
    "papermill": {
     "duration": 0.036807,
     "end_time": "2024-07-28T10:52:22.011081",
     "exception": false,
     "start_time": "2024-07-28T10:52:21.974274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PCD_CAM_VIEW = dict(\n",
    "            up=dict(x=0, y=0, z=1),\n",
    "            eye=dict(x=-0.9, y=0, z=0.2)\n",
    "    )\n",
    "\n",
    "PCD_SCENE=dict(\n",
    "        xaxis=dict(visible=False),\n",
    "        yaxis=dict(visible=False),\n",
    "        zaxis=dict(visible=False,),\n",
    "        aspectmode='manual',\n",
    "        aspectratio=dict(x=1, y=1, z=0.1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b40460ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T10:52:22.131614Z",
     "iopub.status.busy": "2024-07-28T10:52:22.131208Z",
     "iopub.status.idle": "2024-07-28T10:52:22.273286Z",
     "shell.execute_reply": "2024-07-28T10:52:22.272210Z"
    },
    "papermill": {
     "duration": 0.237363,
     "end_time": "2024-07-28T10:52:22.275949",
     "exception": false,
     "start_time": "2024-07-28T10:52:22.038586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import get_lidar3d_plots, get_image2d_plots\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "class Visualizer:\n",
    "    def __init__(self, model_name, fig_width=1000, fig_height=800, pred_box_color='orange', \n",
    "                 waypoints_color = 'red', bbox_2d_color = 'cyan', scene=PCD_SCENE, cam_view=PCD_CAM_VIEW):\n",
    "        self.model_name = model_name\n",
    "\n",
    "        # Create a 2x3 figure, top row for point cloud data\n",
    "        # bottom row for rgb image data\n",
    "        self.fig = make_subplots(rows=3, cols=2,\n",
    "                                 specs=[[{\"type\": \"scatter3d\", \"colspan\": 2}, None], \n",
    "                                        [{}, {\"rowspan\": 2}],\n",
    "                                        [{}, None]], \n",
    "                                row_heights=[0.6, 0.2, 0.2], horizontal_spacing=0.0, vertical_spacing = 0.0)\n",
    "        \n",
    "        self.fig.update_layout(template=\"plotly_dark\", scene=scene, scene_camera = cam_view,\n",
    "                height = fig_height, width = fig_width, autosize=False,\n",
    "                title=f\"END TO END AUTONOMOUS DRIVING {self.model_name}\", title_x=0.5, title_y=0.95,\n",
    "                margin=dict(r=0, b=0, l=0, t=0))\n",
    "        for row in range(2,4):\n",
    "            for col in range(1,3):\n",
    "                self.fig.update_xaxes(showticklabels=False, visible=False, row=row, col=col)\n",
    "                self.fig.update_yaxes(showticklabels=False, visible=False, row=row, col=col)\n",
    "        \n",
    "        # set export image option\n",
    "        self.fig.to_image(format=\"png\", engine=\"kaleido\")\n",
    "        self.pred_color = pred_box_color\n",
    "        self.waypoints_color = waypoints_color\n",
    "        self.box2d_color = bbox_2d_color\n",
    "\n",
    "    def clear_figure_data(self):\n",
    "        self.fig.data = []\n",
    "    \n",
    "    def get_bbox_colors(self, bbox_corners):\n",
    "        return [self.pred_color] * bbox_corners.shape[0] if bbox_corners is not None else None\n",
    "        \n",
    "    def plot_waypoints(self, waypoints):\n",
    "        return go.Mesh3d(x=waypoints[:,0], y=waypoints[:,1], z=waypoints[:,2], \n",
    "                         opacity=0.4, color=self.waypoints_color, \n",
    "                         hoverinfo='skip',showlegend=False)\n",
    "\n",
    "    def add_lidar_plots(self, points, waypoints, pred_corners=None):\n",
    "        lidar_3d_plots = get_lidar3d_plots(points, pc_kwargs=dict(colorscale='viridis', marker_size=0.9),\n",
    "                                   pred_box_corners = pred_corners, \n",
    "                                   pred_box_colors = self.get_bbox_colors(pred_corners))\n",
    "        lidar_3d_plots.append(self.plot_waypoints(waypoints))\n",
    "        for trace in lidar_3d_plots:\n",
    "            self.fig.add_trace(trace, row=1, col=1)\n",
    "\n",
    "    def add_image_plots(self, rgb_image, depth_image, lidar_data, pred_corners_2d):\n",
    "        self.fig.add_trace(get_image2d_plots(rgb_image), row=2, col=1)\n",
    "        \n",
    "        # repeating depth image 3 times to get standard channel\n",
    "        depth_image = np.tile(depth_image[:, :, None], (1,1,3))\n",
    "        self.fig.add_trace(get_image2d_plots(depth_image), row=3, col=1)\n",
    "        \n",
    "        # BEV lidar image with bounding boxes\n",
    "        self.fig.add_trace(get_image2d_plots(lidar_data), row=2, col=2)\n",
    "        box_colors = [self.box2d_color] * len(pred_corners_2d)\n",
    "        for i, obj_i in enumerate(pred_corners_2d):\n",
    "            obj_plots = plot_box_corners2d(obj_i, color = box_colors[i])\n",
    "            for plot in obj_plots:\n",
    "                self.fig.add_trace(plot, row=2, col=2)\n",
    "        \n",
    "    def visualize_predictions(self, points, waypoints, pred_corners_3d, \n",
    "                              rgb_image, depth_image, lidar_data, pred_corners_2d):\n",
    "        # clear previous data and plot lidar, image data\n",
    "        self.clear_figure_data()\n",
    "        self.add_lidar_plots(points=points, waypoints=waypoints, pred_corners=pred_corners_3d)\n",
    "        self.add_image_plots(rgb_image, depth_image, lidar_data, pred_corners_2d)\n",
    "    \n",
    "    def show_figure(self):\n",
    "        self.fig.show()\n",
    "        \n",
    "    def save_to_png(self, output_path):\n",
    "        self.fig.write_image(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2929ec65",
   "metadata": {
    "papermill": {
     "duration": 0.026455,
     "end_time": "2024-07-28T10:52:22.329750",
     "exception": false,
     "start_time": "2024-07-28T10:52:22.303295",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Demo video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ce04ab4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T10:52:22.387746Z",
     "iopub.status.busy": "2024-07-28T10:52:22.387390Z",
     "iopub.status.idle": "2024-07-28T10:52:22.399154Z",
     "shell.execute_reply": "2024-07-28T10:52:22.398053Z"
    },
    "papermill": {
     "duration": 0.044211,
     "end_time": "2024-07-28T10:52:22.401707",
     "exception": false,
     "start_time": "2024-07-28T10:52:22.357496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Class activation map imports\n",
    "target_layers = [model._model.image_encoder.features.layer4]\n",
    "from e2e_cam import EigenCAM, PlannerTarget, show_cam_on_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cafb6176",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T10:52:22.461476Z",
     "iopub.status.busy": "2024-07-28T10:52:22.461026Z",
     "iopub.status.idle": "2024-07-28T11:00:02.925251Z",
     "shell.execute_reply": "2024-07-28T11:00:02.919313Z"
    },
    "papermill": {
     "duration": 460.502995,
     "end_time": "2024-07-28T11:00:02.933273",
     "exception": false,
     "start_time": "2024-07-28T10:52:22.430278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/48 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/mmdet/models/utils/gaussian_target.py:227: UserWarning:\n",
      "\n",
      "__floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/mmdet/models/utils/gaussian_target.py:229: UserWarning:\n",
      "\n",
      "__floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "\n",
      "100%|██████████| 48/48 [07:37<00:00,  9.53s/it]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib agg\n",
    "visualizer = Visualizer(model_name='TRANSFUSER')\n",
    "\n",
    "from utils import boxes_to_corners_3d\n",
    "\n",
    "frameIdx = 0\n",
    "with EigenCAM(model=model, target_layers=target_layers) as cam:\n",
    "    for data in tqdm(dataloader_demo):\n",
    "        # load data to device, according to type\n",
    "        for k in ['rgb', 'depth', 'lidar', 'label', 'ego_waypoint', \\\n",
    "                  'target_point', 'target_point_image', 'speed']:\n",
    "            data[k] = data[k].to(device, torch.float32)\n",
    "        for k in ['semantic', 'bev']:\n",
    "            data[k] = data[k].to(device, torch.long)\n",
    "\n",
    "        # get model predictions\n",
    "        targets = [PlannerTarget(data['ego_waypoint'])]\n",
    "        grayscale_cam = cam(input_data=data, targets=targets, key='rgb')\n",
    "        outputs = cam.outputs[1]\n",
    "\n",
    "        # iterate through each sample in batch \n",
    "        bs = data['rgb'].shape[0]\n",
    "        for i in range(bs):\n",
    "            # input data\n",
    "            rgb_image = data['rgb'][i].permute(1, 2, 0).detach().cpu().numpy()\n",
    "            tgt_waypoints = data['ego_waypoint'][i].detach().cpu().numpy()\n",
    "            lidar_pc = data['raw_lidar'][i].detach().cpu().numpy()\n",
    "            num_points = data['num_raw_lidar_points'].detach().cpu().numpy()[i]\n",
    "            lidar_pc = lidar_pc[:num_points, :]\n",
    "\n",
    "            # bev lidar image\n",
    "            lidar_data = data['lidar'][i].detach().cpu().numpy().transpose(1,2,0)\n",
    "            lidar_data = (lidar_data * 255).astype(np.uint8)\n",
    "\n",
    "            # MODEL PREDICTIONS\n",
    "            pred_waypoints = outputs['pred_wp'][i]\n",
    "            pred_waypoints[:, 1] *= -1 \n",
    "            pred_lanepoints = generate_lane_points(pred_waypoints)\n",
    "\n",
    "            ## AUXILLARY TASK PREDICTIONS\n",
    "\n",
    "            ## bounding boxes\n",
    "            pred_boxes = outputs['detections'][i]\n",
    "            pred_3d_boxes = convert_to_3d_bboxes(pred_boxes)\n",
    "            pred_corners_3d = boxes_to_corners_3d(pred_3d_boxes)\n",
    "\n",
    "            # project to bev image space\n",
    "            pred_corners_2d = [get_rotated_bbox(bbox)[:, :2] for bbox in pred_boxes]\n",
    "\n",
    "            ## depth information\n",
    "            pred_depth = (outputs['pred_depth'][i] * 255).astype(np.uint8)\n",
    "            pred_bev = outputs['pred_bev'][i].argmax(axis=0).astype(np.uint8)\n",
    "            \n",
    "            # Class activation map\n",
    "            rgb_image = rgb_image / 255.0\n",
    "            grayscale_cam_i = grayscale_cam[i]\n",
    "            cam_image = show_cam_on_image(rgb_image, grayscale_cam_i, use_rgb=True)\n",
    "\n",
    "            # plot all data\n",
    "            visualizer.visualize_predictions(lidar_pc, pred_lanepoints, pred_corners_3d,\n",
    "                                             cam_image, pred_depth, lidar_data, \n",
    "                                             pred_corners_2d = pred_corners_2d)\n",
    "\n",
    "            # save figure\n",
    "            visualizer.save_to_png(f\"Frame{frameIdx}.png\")\n",
    "            frameIdx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0484ae7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T11:00:03.078740Z",
     "iopub.status.busy": "2024-07-28T11:00:03.078201Z",
     "iopub.status.idle": "2024-07-28T11:00:03.126559Z",
     "shell.execute_reply": "2024-07-28T11:00:03.125242Z"
    },
    "papermill": {
     "duration": 0.122526,
     "end_time": "2024-07-28T11:00:03.131386",
     "exception": false,
     "start_time": "2024-07-28T11:00:03.008860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_images_to_video(images_dir, output_video_path, fps : int = 8):\n",
    "    input_images = [os.path.join(images_dir, *[x]) for x in sorted(os.listdir(images_dir)) if x.endswith('png')]\n",
    "    \n",
    "    if(len(input_images) > 0):\n",
    "        sample_image = cv2.imread(input_images[0])\n",
    "        height, width, _ = sample_image.shape\n",
    "        \n",
    "        # handles for input output videos\n",
    "        output_handle = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'DIVX'), fps, (width, height))\n",
    "    \n",
    "        # create progress bar\n",
    "        num_frames = int(len(input_images))\n",
    "        pbar = tqdm(total = num_frames, position=0, leave=True)\n",
    "\n",
    "        for i in tqdm(range(num_frames), position=0, leave=True):\n",
    "            frame = cv2.imread(input_images[i])\n",
    "            output_handle.write(frame)\n",
    "            pbar.update(1)\n",
    "\n",
    "        # release the output video handler\n",
    "        output_handle.release()\n",
    "                \n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66f8f895",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T11:00:03.241448Z",
     "iopub.status.busy": "2024-07-28T11:00:03.240987Z",
     "iopub.status.idle": "2024-07-28T11:00:05.503423Z",
     "shell.execute_reply": "2024-07-28T11:00:05.502179Z"
    },
    "papermill": {
     "duration": 2.301479,
     "end_time": "2024-07-28T11:00:05.505760",
     "exception": false,
     "start_time": "2024-07-28T11:00:03.204281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|██████████| 95/95 [00:02<00:00, 43.95it/s]\n",
      "100%|██████████| 95/95 [00:02<00:00, 43.79it/s]\n"
     ]
    }
   ],
   "source": [
    "FPS = 6\n",
    "convert_images_to_video('./', f'scenario1_route0_{model.pred_len}pts_{FPS}fps.mp4', fps=FPS)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4849257,
     "sourceId": 8287109,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4922400,
     "sourceId": 8287377,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4849261,
     "sourceId": 9051268,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 600.972899,
   "end_time": "2024-07-28T11:00:08.274486",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-28T10:50:07.301587",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "22f5eff27416482695facf876bc8c880": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2b3899802ce54833a3a6f951fb8c10db": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3aa2f14c125442f4aceefa021eb5d8fb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d17fc26965db43c3b7cb39a8de93b291",
       "placeholder": "​",
       "style": "IPY_MODEL_2b3899802ce54833a3a6f951fb8c10db",
       "value": " 78.1M/78.1M [00:04&lt;00:00, 22.3MB/s]"
      }
     },
     "6dd9600a470d4e39a8cedcc8329dc154": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d2ff6ad179b84cf79ff6aa338d70a8f7",
        "IPY_MODEL_b3e4041ab1324a83ab0836f40a9310e4",
        "IPY_MODEL_3aa2f14c125442f4aceefa021eb5d8fb"
       ],
       "layout": "IPY_MODEL_cd58e551608147c3b2bbc31e2d3ff172"
      }
     },
     "8a9e15c20c76402ba2a44f0473591c85": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9cfa5315811944a8b8d59f8e501b3684": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b3e4041ab1324a83ab0836f40a9310e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_22f5eff27416482695facf876bc8c880",
       "max": 78055620.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f1f3dc4434ad4e4b8e29cc777caed071",
       "value": 78055620.0
      }
     },
     "cd58e551608147c3b2bbc31e2d3ff172": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d17fc26965db43c3b7cb39a8de93b291": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d2ff6ad179b84cf79ff6aa338d70a8f7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8a9e15c20c76402ba2a44f0473591c85",
       "placeholder": "​",
       "style": "IPY_MODEL_9cfa5315811944a8b8d59f8e501b3684",
       "value": "model.safetensors: 100%"
      }
     },
     "f1f3dc4434ad4e4b8e29cc777caed071": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
