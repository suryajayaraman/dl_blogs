{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec7ddb85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T11:03:08.359314Z",
     "iopub.status.busy": "2024-07-28T11:03:08.358917Z",
     "iopub.status.idle": "2024-07-28T11:04:41.837694Z",
     "shell.execute_reply": "2024-07-28T11:04:41.836413Z"
    },
    "papermill": {
     "duration": 93.489149,
     "end_time": "2024-07-28T11:04:41.840413",
     "exception": false,
     "start_time": "2024-07-28T11:03:08.351264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu\r\n",
      "Collecting torch==1.11.0+cpu\r\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-1.11.0%2Bcpu-cp310-cp310-linux_x86_64.whl (169.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.2/169.2 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting torchvision==0.12.0+cpu\r\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.12.0%2Bcpu-cp310-cp310-linux_x86_64.whl (14.7 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==1.11.0+cpu) (4.9.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision==0.12.0+cpu) (1.26.4)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision==0.12.0+cpu) (2.31.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.12.0+cpu) (9.5.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.12.0+cpu) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.12.0+cpu) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.12.0+cpu) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.12.0+cpu) (2024.2.2)\r\n",
      "Installing collected packages: torch, torchvision\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.1.2+cpu\r\n",
      "    Uninstalling torch-2.1.2+cpu:\r\n",
      "      Successfully uninstalled torch-2.1.2+cpu\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.16.2+cpu\r\n",
      "    Uninstalling torchvision-0.16.2+cpu:\r\n",
      "      Successfully uninstalled torchvision-0.16.2+cpu\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "pytorch-lightning 2.2.2 requires torch>=1.13.0, but you have torch 1.11.0+cpu which is incompatible.\r\n",
      "stable-baselines3 2.1.0 requires torch>=1.13, but you have torch 1.11.0+cpu which is incompatible.\r\n",
      "torchaudio 2.1.2+cpu requires torch==2.1.2, but you have torch 1.11.0+cpu which is incompatible.\r\n",
      "torchdata 0.7.1 requires torch>=2, but you have torch 1.11.0+cpu which is incompatible.\r\n",
      "torchtext 0.16.2+cpu requires torch==2.1.2, but you have torch 1.11.0+cpu which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed torch-1.11.0+cpu torchvision-0.12.0+cpu\r\n",
      "Looking in links: https://download.openmmlab.com/mmcv/dist/cpu/torch1.11/index.html\r\n",
      "Collecting mmcv-full==1.5.3\r\n",
      "  Downloading https://download.openmmlab.com/mmcv/dist/cpu/torch1.11.0/mmcv_full-1.5.3-cp310-cp310-manylinux1_x86_64.whl (21.7 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.7/21.7 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting addict (from mmcv-full==1.5.3)\r\n",
      "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mmcv-full==1.5.3) (1.26.4)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from mmcv-full==1.5.3) (21.3)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from mmcv-full==1.5.3) (9.5.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from mmcv-full==1.5.3) (6.0.1)\r\n",
      "Requirement already satisfied: yapf in /opt/conda/lib/python3.10/site-packages (from mmcv-full==1.5.3) (0.40.2)\r\n",
      "Requirement already satisfied: opencv-python>=3 in /opt/conda/lib/python3.10/site-packages (from mmcv-full==1.5.3) (4.9.0.80)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->mmcv-full==1.5.3) (3.1.1)\r\n",
      "Requirement already satisfied: importlib-metadata>=6.6.0 in /opt/conda/lib/python3.10/site-packages (from yapf->mmcv-full==1.5.3) (6.11.0)\r\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmcv-full==1.5.3) (4.2.0)\r\n",
      "Requirement already satisfied: tomli>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmcv-full==1.5.3) (2.0.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=6.6.0->yapf->mmcv-full==1.5.3) (3.17.0)\r\n",
      "Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\r\n",
      "Installing collected packages: addict, mmcv-full\r\n",
      "Successfully installed addict-2.4.0 mmcv-full-1.5.3\r\n",
      "Looking in links: https://download.openmmlab.com/mmdet/dist/cpu/torch1.11/index.html\r\n",
      "Collecting mmdet==2.25.0\r\n",
      "  Downloading mmdet-2.25.0-py3-none-any.whl.metadata (20 kB)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mmdet==2.25.0) (3.7.5)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mmdet==2.25.0) (1.26.4)\r\n",
      "Collecting pycocotools (from mmdet==2.25.0)\r\n",
      "  Downloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from mmdet==2.25.0) (1.16.0)\r\n",
      "Collecting terminaltables (from mmdet==2.25.0)\r\n",
      "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl.metadata (3.5 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmdet==2.25.0) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmdet==2.25.0) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmdet==2.25.0) (4.47.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmdet==2.25.0) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmdet==2.25.0) (21.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmdet==2.25.0) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmdet==2.25.0) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmdet==2.25.0) (2.9.0.post0)\r\n",
      "Downloading mmdet-2.25.0-py3-none-any.whl (1.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.8/427.8 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\r\n",
      "Installing collected packages: terminaltables, pycocotools, mmdet\r\n",
      "Successfully installed mmdet-2.25.0 pycocotools-2.0.8 terminaltables-3.1.10\r\n",
      "Collecting kaleido\r\n",
      "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl.metadata (15 kB)\r\n",
      "Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: kaleido\r\n",
      "Successfully installed kaleido-0.2.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.11.0+cpu torchvision==0.12.0+cpu --extra-index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install mmcv-full==1.5.3 -f https://download.openmmlab.com/mmcv/dist/cpu/torch1.11/index.html\n",
    "!pip install mmdet==2.25.0 -f https://download.openmmlab.com/mmdet/dist/cpu/torch1.11/index.html\n",
    "!pip install kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62453eb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T11:04:41.879350Z",
     "iopub.status.busy": "2024-07-28T11:04:41.878935Z",
     "iopub.status.idle": "2024-07-28T11:04:42.782956Z",
     "shell.execute_reply": "2024-07-28T11:04:42.781889Z"
    },
    "papermill": {
     "duration": 0.926555,
     "end_time": "2024-07-28T11:04:42.785420",
     "exception": false,
     "start_time": "2024-07-28T11:04:41.858865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import random\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(suppress=True, precision=5)\n",
    "sys.path.append('/kaggle/input/transfuser-e2e-scripts')\n",
    "\n",
    "# dl imports\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb290e6",
   "metadata": {
    "papermill": {
     "duration": 0.018053,
     "end_time": "2024-07-28T11:04:42.820898",
     "exception": false,
     "start_time": "2024-07-28T11:04:42.802845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CARLA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ea0ad63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T11:04:42.858324Z",
     "iopub.status.busy": "2024-07-28T11:04:42.857319Z",
     "iopub.status.idle": "2024-07-28T11:04:43.430310Z",
     "shell.execute_reply": "2024-07-28T11:04:43.429147Z"
    },
    "papermill": {
     "duration": 0.594496,
     "end_time": "2024-07-28T11:04:43.432815",
     "exception": false,
     "start_time": "2024-07-28T11:04:42.838319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from config import GlobalConfig\n",
    "from data import CARLA_Data\n",
    "\n",
    "config = GlobalConfig()\n",
    "config.pred_len = 7\n",
    "\n",
    "FPS = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b206987",
   "metadata": {
    "papermill": {
     "duration": 0.017048,
     "end_time": "2024-07-28T11:04:43.467867",
     "exception": false,
     "start_time": "2024-07-28T11:04:43.450819",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Create pytorch style dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffb6117a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T11:04:43.505142Z",
     "iopub.status.busy": "2024-07-28T11:04:43.504430Z",
     "iopub.status.idle": "2024-07-28T11:04:43.509636Z",
     "shell.execute_reply": "2024-07-28T11:04:43.508596Z"
    },
    "papermill": {
     "duration": 0.02625,
     "end_time": "2024-07-28T11:04:43.512009",
     "exception": false,
     "start_time": "2024-07-28T11:04:43.485759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79812708",
   "metadata": {
    "papermill": {
     "duration": 0.017244,
     "end_time": "2024-07-28T11:04:43.547292",
     "exception": false,
     "start_time": "2024-07-28T11:04:43.530048",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be756a79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T11:04:43.584405Z",
     "iopub.status.busy": "2024-07-28T11:04:43.583360Z",
     "iopub.status.idle": "2024-07-28T11:05:00.124838Z",
     "shell.execute_reply": "2024-07-28T11:05:00.123711Z"
    },
    "papermill": {
     "duration": 16.562704,
     "end_time": "2024-07-28T11:05:00.127260",
     "exception": false,
     "start_time": "2024-07-28T11:04:43.564556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0603468804ba4fdab4cfb8bca81ab58f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/78.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "from model import LidarCenterNet\n",
    "model = LidarCenterNet(config, device, config.backbone, image_architecture='regnety_032', \n",
    "                           lidar_architecture='regnety_032', estimate_loss=False)\n",
    "model.to(device);\n",
    "model.config.debug = True\n",
    "\n",
    "model.eval();\n",
    "checkpt = torch.load('/kaggle/input/carla-transfuser-regnet032/transfuser_regnet032_seed1_39.pth', map_location=device)\n",
    "model.load_state_dict(checkpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299ff548",
   "metadata": {
    "papermill": {
     "duration": 0.019109,
     "end_time": "2024-07-28T11:05:00.169469",
     "exception": false,
     "start_time": "2024-07-28T11:05:00.150360",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f03c8f48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T11:05:00.206784Z",
     "iopub.status.busy": "2024-07-28T11:05:00.205793Z",
     "iopub.status.idle": "2024-07-28T11:05:00.213289Z",
     "shell.execute_reply": "2024-07-28T11:05:00.212115Z"
    },
    "papermill": {
     "duration": 0.028737,
     "end_time": "2024-07-28T11:05:00.215592",
     "exception": false,
     "start_time": "2024-07-28T11:05:00.186855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import VEHICLE_TO_LIDAR_FWD, LIDAR_HEIGHT\n",
    "\n",
    "def generate_lane_points(waypoints, lane_width = 1.0):\n",
    "    # input waypoints are 2d coordinates of centerline (N,2)\n",
    "    # this function generates left and right lane corners\n",
    "    # by subtracting and adding half lane width. We convert\n",
    "    # to 3D Lidar coordinates by placing points at ground level\n",
    "\n",
    "    n_points = waypoints.shape[0]\n",
    "    lane_points = np.zeros((n_points * 2 , 3))\n",
    "    \n",
    "    # vehicle to lidar frame\n",
    "    lane_points[:n_points, 0] = waypoints[:,0] + VEHICLE_TO_LIDAR_FWD\n",
    "    lane_points[n_points:, 0] = waypoints[:,0] + VEHICLE_TO_LIDAR_FWD\n",
    "    \n",
    "    # left and right lanes\n",
    "    lane_points[:n_points,1] = waypoints[:,1] - (lane_width * 0.5)\n",
    "    lane_points[n_points:,1] = waypoints[:,1] + (lane_width * 0.5)\n",
    "    \n",
    "    # fixed height\n",
    "    lane_points[:,2] = -LIDAR_HEIGHT\n",
    "    return lane_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "080b128d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T11:05:00.252531Z",
     "iopub.status.busy": "2024-07-28T11:05:00.252113Z",
     "iopub.status.idle": "2024-07-28T11:05:00.260522Z",
     "shell.execute_reply": "2024-07-28T11:05:00.259454Z"
    },
    "papermill": {
     "duration": 0.029545,
     "end_time": "2024-07-28T11:05:00.262882",
     "exception": false,
     "start_time": "2024-07-28T11:05:00.233337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bev_to_lidar = np.array([\n",
    "            [0, -(1/8.0), 32],\n",
    "            [-(1/8.0), 0, 16],\n",
    "            [0 , 0, 1]\n",
    "])\n",
    "\n",
    "\n",
    "def convert_to_3d_bboxes(boxes_2d):\n",
    "    n_boxes = boxes_2d.shape[0]\n",
    "    bbox_3d = np.zeros((n_boxes, 7))\n",
    "\n",
    "    # xy position from bev pixels to metres\n",
    "    homogenous_coordinates = np.hstack([boxes_2d[:, :2], np.ones((n_boxes, 1))])\n",
    "    bbox_3d[:, :2] = (bev_to_lidar @ homogenous_coordinates.T).T[:, :2]\n",
    "    bbox_3d[:, 3] = boxes_2d[:, 3] / 8  # length \n",
    "    bbox_3d[:, 4] = boxes_2d[:, 2] / 8  # width\n",
    "    bbox_3d[:, 6] = -boxes_2d[:, 4]      # yaw\n",
    "\n",
    "    # hardcoding z values\n",
    "    bbox_3d[:, 2] = -1.25\n",
    "    bbox_3d[:, 5] = 2.5\n",
    "    return bbox_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d79b02e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T11:05:00.300091Z",
     "iopub.status.busy": "2024-07-28T11:05:00.299671Z",
     "iopub.status.idle": "2024-07-28T11:05:00.311856Z",
     "shell.execute_reply": "2024-07-28T11:05:00.310445Z"
    },
    "papermill": {
     "duration": 0.033648,
     "end_time": "2024-07-28T11:05:00.314410",
     "exception": false,
     "start_time": "2024-07-28T11:05:00.280762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_rotated_bbox(bbox):\n",
    "    x, y, w, h, yaw, _, _  =  bbox\n",
    "\n",
    "    bbox = np.array([[h,   w, 1],\n",
    "                     [h,  -w, 1],\n",
    "                     [-h, -w, 1],\n",
    "                     [-h,  w, 1],\n",
    "                ])\n",
    "    \n",
    "    # The height and width of the bounding box value was changed by this factor \n",
    "    # during data collection. Fix that for future datasets and remove    \n",
    "    bbox[:, :2] /= 2\n",
    "    bbox[:, :2] = bbox[:, [1, 0]]\n",
    "\n",
    "    c, s = np.cos(yaw), np.sin(yaw)\n",
    "    # use y x because coordinate is changed\n",
    "    r1_to_world = np.array([[c, -s, x], [s, c, y], [0, 0, 1]])\n",
    "    bbox = r1_to_world @ bbox.T\n",
    "    bbox = bbox.T\n",
    "    bbox = np.clip(bbox, 0, 256)\n",
    "    return bbox\n",
    "\n",
    "def get_scatter_plot(x,y, mode='lines', marker_size=2, color=None, **kwargs):\n",
    "    return go.Scatter(x=x, y=y, mode=mode, hoverinfo='skip',showlegend=False, \n",
    "                        marker = dict(size=marker_size, color=color), **kwargs)\n",
    "\n",
    "def plot_box_corners2d(box2d, color,**kwargs):\n",
    "    return [\n",
    "        get_scatter_plot([box2d[0,0], box2d[1,0]], [box2d[0,1], box2d[1,1]], color=color, **kwargs),\n",
    "        get_scatter_plot([box2d[1,0], box2d[2,0]], [box2d[1,1], box2d[2,1]], color=color, **kwargs),\n",
    "        get_scatter_plot([box2d[2,0], box2d[3,0]], [box2d[2,1], box2d[3,1]], color=color, **kwargs),\n",
    "        get_scatter_plot([box2d[3,0], box2d[0,0]], [box2d[3,1], box2d[0,1]], color=color, **kwargs),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd43754",
   "metadata": {
    "papermill": {
     "duration": 0.017334,
     "end_time": "2024-07-28T11:05:00.349602",
     "exception": false,
     "start_time": "2024-07-28T11:05:00.332268",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Visualization class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0faad927",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T11:05:00.386839Z",
     "iopub.status.busy": "2024-07-28T11:05:00.386043Z",
     "iopub.status.idle": "2024-07-28T11:05:00.392309Z",
     "shell.execute_reply": "2024-07-28T11:05:00.391149Z"
    },
    "papermill": {
     "duration": 0.027055,
     "end_time": "2024-07-28T11:05:00.394404",
     "exception": false,
     "start_time": "2024-07-28T11:05:00.367349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PCD_CAM_VIEW = dict(\n",
    "            up=dict(x=0, y=0, z=1),\n",
    "            eye=dict(x=-0.9, y=0, z=0.2)\n",
    "    )\n",
    "\n",
    "PCD_SCENE=dict(\n",
    "        xaxis=dict(visible=False),\n",
    "        yaxis=dict(visible=False),\n",
    "        zaxis=dict(visible=False,),\n",
    "        aspectmode='manual',\n",
    "        aspectratio=dict(x=1, y=1, z=0.1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9958b5ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T11:05:00.431408Z",
     "iopub.status.busy": "2024-07-28T11:05:00.431042Z",
     "iopub.status.idle": "2024-07-28T11:05:00.569294Z",
     "shell.execute_reply": "2024-07-28T11:05:00.567983Z"
    },
    "papermill": {
     "duration": 0.159968,
     "end_time": "2024-07-28T11:05:00.571988",
     "exception": false,
     "start_time": "2024-07-28T11:05:00.412020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import get_lidar3d_plots, get_image2d_plots\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "class Visualizer:\n",
    "    def __init__(self, model_name, fig_width=1000, fig_height=800, pred_box_color='orange', \n",
    "                 waypoints_color = 'red', bbox_2d_color = 'cyan', scene=PCD_SCENE, cam_view=PCD_CAM_VIEW):\n",
    "        self.model_name = model_name\n",
    "\n",
    "        # Create a 2x3 figure, top row for point cloud data\n",
    "        # bottom row for rgb image data\n",
    "        self.fig = make_subplots(rows=3, cols=2,\n",
    "                                 specs=[[{\"type\": \"scatter3d\", \"colspan\": 2}, None], \n",
    "                                        [{}, {\"rowspan\": 2}],\n",
    "                                        [{}, None]], \n",
    "                                row_heights=[0.6, 0.2, 0.2], horizontal_spacing=0.0, vertical_spacing = 0.0)\n",
    "        \n",
    "        self.fig.update_layout(template=\"plotly_dark\", scene=scene, scene_camera = cam_view,\n",
    "                height = fig_height, width = fig_width, autosize=False,\n",
    "                title=f\"END TO END AUTONOMOUS DRIVING {self.model_name}\", title_x=0.5, title_y=0.95,\n",
    "                margin=dict(r=0, b=0, l=0, t=0))\n",
    "        for row in range(2,4):\n",
    "            for col in range(1,3):\n",
    "                self.fig.update_xaxes(showticklabels=False, visible=False, row=row, col=col)\n",
    "                self.fig.update_yaxes(showticklabels=False, visible=False, row=row, col=col)\n",
    "        \n",
    "        # set export image option\n",
    "        self.fig.to_image(format=\"png\", engine=\"kaleido\")\n",
    "        self.pred_color = pred_box_color\n",
    "        self.waypoints_color = waypoints_color\n",
    "        self.box2d_color = bbox_2d_color\n",
    "\n",
    "    def clear_figure_data(self):\n",
    "        self.fig.data = []\n",
    "    \n",
    "    def get_bbox_colors(self, bbox_corners):\n",
    "        return [self.pred_color] * bbox_corners.shape[0] if bbox_corners is not None else None\n",
    "        \n",
    "    def plot_waypoints(self, waypoints):\n",
    "        return go.Mesh3d(x=waypoints[:,0], y=waypoints[:,1], z=waypoints[:,2], \n",
    "                         opacity=0.4, color=self.waypoints_color, \n",
    "                         hoverinfo='skip',showlegend=False)\n",
    "\n",
    "    def add_lidar_plots(self, points, waypoints, pred_corners=None):\n",
    "        lidar_3d_plots = get_lidar3d_plots(points, pc_kwargs=dict(colorscale='viridis', marker_size=0.9),\n",
    "                                   pred_box_corners = pred_corners, \n",
    "                                   pred_box_colors = self.get_bbox_colors(pred_corners))\n",
    "        lidar_3d_plots.append(self.plot_waypoints(waypoints))\n",
    "        for trace in lidar_3d_plots:\n",
    "            self.fig.add_trace(trace, row=1, col=1)\n",
    "\n",
    "    def add_image_plots(self, rgb_image, depth_image, lidar_data, pred_corners_2d):\n",
    "        self.fig.add_trace(get_image2d_plots(rgb_image), row=2, col=1)\n",
    "        \n",
    "        # repeating depth image 3 times to get standard channel\n",
    "        depth_image = np.tile(depth_image[:, :, None], (1,1,3))\n",
    "        self.fig.add_trace(get_image2d_plots(depth_image), row=3, col=1)\n",
    "        \n",
    "        # BEV lidar image with bounding boxes\n",
    "        self.fig.add_trace(get_image2d_plots(lidar_data), row=2, col=2)\n",
    "        box_colors = [self.box2d_color] * len(pred_corners_2d)\n",
    "        for i, obj_i in enumerate(pred_corners_2d):\n",
    "            obj_plots = plot_box_corners2d(obj_i, color = box_colors[i])\n",
    "            for plot in obj_plots:\n",
    "                self.fig.add_trace(plot, row=2, col=2)\n",
    "        \n",
    "    def visualize_predictions(self, points, waypoints, pred_corners_3d, \n",
    "                              rgb_image, depth_image, lidar_data, pred_corners_2d):\n",
    "        # clear previous data and plot lidar, image data\n",
    "        self.clear_figure_data()\n",
    "        self.add_lidar_plots(points=points, waypoints=waypoints, pred_corners=pred_corners_3d)\n",
    "        self.add_image_plots(rgb_image, depth_image, lidar_data, pred_corners_2d)\n",
    "    \n",
    "    def show_figure(self):\n",
    "        self.fig.show()\n",
    "        \n",
    "    def save_to_png(self, output_path):\n",
    "        self.fig.write_image(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb81da9",
   "metadata": {
    "papermill": {
     "duration": 0.017951,
     "end_time": "2024-07-28T11:05:00.607869",
     "exception": false,
     "start_time": "2024-07-28T11:05:00.589918",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Demo video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "723dc890",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T11:05:00.644709Z",
     "iopub.status.busy": "2024-07-28T11:05:00.644311Z",
     "iopub.status.idle": "2024-07-28T11:05:00.657095Z",
     "shell.execute_reply": "2024-07-28T11:05:00.655940Z"
    },
    "papermill": {
     "duration": 0.034101,
     "end_time": "2024-07-28T11:05:00.659545",
     "exception": false,
     "start_time": "2024-07-28T11:05:00.625444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Eigen CAM imports\n",
    "from e2e_cam import EigenCAM, PlannerTarget, show_cam_on_image\n",
    "\n",
    "# which layers should be focus on\n",
    "target_layers = [model._model.image_encoder.features.layer4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cdbace2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T11:05:00.696553Z",
     "iopub.status.busy": "2024-07-28T11:05:00.696172Z",
     "iopub.status.idle": "2024-07-28T11:05:00.712110Z",
     "shell.execute_reply": "2024-07-28T11:05:00.710895Z"
    },
    "papermill": {
     "duration": 0.037496,
     "end_time": "2024-07-28T11:05:00.714755",
     "exception": false,
     "start_time": "2024-07-28T11:05:00.677259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from utils import boxes_to_corners_3d\n",
    "\n",
    "def write_model_predictions(dataloader_demo, output_dir):\n",
    "    frameIdx = 0\n",
    "        \n",
    "    with EigenCAM(model=model, target_layers=target_layers) as cam:    \n",
    "        for data in tqdm(dataloader_demo):\n",
    "            # load data to device, according to type\n",
    "            for k in ['rgb', 'depth', 'lidar', 'label', 'ego_waypoint', \\\n",
    "                      'target_point', 'target_point_image', 'speed']:\n",
    "                data[k] = data[k].to(device, torch.float32)\n",
    "            for k in ['semantic', 'bev']:\n",
    "                data[k] = data[k].to(device, torch.long)\n",
    "\n",
    "            # get model predictions\n",
    "            targets = [PlannerTarget(data['ego_waypoint'])]            \n",
    "            grayscale_cam = cam(input_data=data, targets=targets, key='rgb')\n",
    "            outputs = cam.outputs[1]\n",
    "\n",
    "            # iterate through each sample in batch \n",
    "            bs = data['rgb'].shape[0]\n",
    "            for i in range(bs):\n",
    "                # input data\n",
    "                rgb_image = data['rgb'][i].permute(1, 2, 0).detach().cpu().numpy()\n",
    "                tgt_waypoints = data['ego_waypoint'][i].detach().cpu().numpy()\n",
    "                lidar_pc = data['raw_lidar'][i].detach().cpu().numpy()\n",
    "                num_points = data['num_raw_lidar_points'].detach().cpu().numpy()[i]\n",
    "                lidar_pc = lidar_pc[:num_points, :]\n",
    "\n",
    "                # bev lidar image\n",
    "                lidar_data = data['lidar'][i].detach().cpu().numpy().transpose(1,2,0)\n",
    "                lidar_data = (lidar_data * 255).astype(np.uint8)\n",
    "\n",
    "                # MODEL PREDICTIONS\n",
    "                pred_waypoints = outputs['pred_wp'][i]\n",
    "                pred_waypoints[:,1] *= -1\n",
    "                pred_lanepoints = generate_lane_points(pred_waypoints)\n",
    "\n",
    "                ## AUXILLARY TASK PREDICTIONS\n",
    "\n",
    "                ## bounding boxes\n",
    "                pred_boxes = outputs['detections'][i]\n",
    "                pred_3d_boxes = convert_to_3d_bboxes(pred_boxes)\n",
    "                pred_corners_3d = boxes_to_corners_3d(pred_3d_boxes)\n",
    "\n",
    "                # project to bev image space\n",
    "                pred_corners_2d = [get_rotated_bbox(bbox)[:, :2] for bbox in pred_boxes]\n",
    "\n",
    "                ## depth information\n",
    "                pred_depth = (outputs['pred_depth'][i] * 255).astype(np.uint8)\n",
    "                pred_bev = outputs['pred_bev'][i].argmax(axis=0).astype(np.uint8)\n",
    "                \n",
    "                # class activation maps\n",
    "                rgb_image = rgb_image / 255.0\n",
    "                cam_image = show_cam_on_image(rgb_image, grayscale_cam[i], use_rgb=True)\n",
    "                    \n",
    "                # plot all data\n",
    "                visualizer.visualize_predictions(lidar_pc, pred_lanepoints, pred_corners_3d,\n",
    "                                                 cam_image, pred_depth, lidar_data, \n",
    "                                                 pred_corners_2d = pred_corners_2d)\n",
    "                # save figure\n",
    "                visualizer.save_to_png(os.path.join(output_dir, f\"Frame{frameIdx}.png\"))\n",
    "                frameIdx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08351806",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T11:05:00.752232Z",
     "iopub.status.busy": "2024-07-28T11:05:00.751833Z",
     "iopub.status.idle": "2024-07-28T11:05:00.760064Z",
     "shell.execute_reply": "2024-07-28T11:05:00.759005Z"
    },
    "papermill": {
     "duration": 0.029457,
     "end_time": "2024-07-28T11:05:00.762226",
     "exception": false,
     "start_time": "2024-07-28T11:05:00.732769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_images_to_video(images_dir, output_video_path, fps : int = 8):\n",
    "    input_images = [os.path.join(images_dir, *[x]) for x in sorted(os.listdir(images_dir)) if x.endswith('png')]\n",
    "    \n",
    "    if(len(input_images) > 0):\n",
    "        sample_image = cv2.imread(input_images[0])\n",
    "        height, width, _ = sample_image.shape\n",
    "        \n",
    "        # handles for input output videos\n",
    "        output_handle = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'DIVX'), fps, (width, height))\n",
    "\n",
    "        # create progress bar\n",
    "        num_frames = int(len(input_images))\n",
    "        pbar = tqdm(total = num_frames, position=0, leave=True)\n",
    "\n",
    "        for i in tqdm(range(num_frames), position=0, leave=True):\n",
    "            frame = cv2.imread(input_images[i])\n",
    "            output_handle.write(frame)\n",
    "            pbar.update(1)\n",
    "\n",
    "        # release the output video handler\n",
    "        output_handle.release()\n",
    "                \n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ce79b6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T11:05:00.799244Z",
     "iopub.status.busy": "2024-07-28T11:05:00.798567Z",
     "iopub.status.idle": "2024-07-28T11:05:00.804449Z",
     "shell.execute_reply": "2024-07-28T11:05:00.803376Z"
    },
    "papermill": {
     "duration": 0.026689,
     "end_time": "2024-07-28T11:05:00.806571",
     "exception": false,
     "start_time": "2024-07-28T11:05:00.779882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_route_name(folder):\n",
    "    contains_routes = [x for x in folder.split('_') if 'route' in x and len(x) ==6]\n",
    "    if 'routes' in contains_routes:\n",
    "        contains_routes.remove('routes')\n",
    "    return contains_routes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a94e155",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T11:05:00.843589Z",
     "iopub.status.busy": "2024-07-28T11:05:00.843188Z",
     "iopub.status.idle": "2024-07-28T13:20:42.910858Z",
     "shell.execute_reply": "2024-07-28T13:20:42.909452Z"
    },
    "papermill": {
     "duration": 8142.088967,
     "end_time": "2024-07-28T13:20:42.913178",
     "exception": false,
     "start_time": "2024-07-28T11:05:00.824211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 34.46it/s]\n",
      "There are 95 samples in Demo dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/48 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/mmdet/models/utils/gaussian_target.py:227: UserWarning:\n",
      "\n",
      "__floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/mmdet/models/utils/gaussian_target.py:229: UserWarning:\n",
      "\n",
      "__floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "\n",
      "100%|██████████| 48/48 [07:27<00:00,  9.32s/it]\n",
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|██████████| 95/95 [00:01<00:00, 53.15it/s]\n",
      "100%|██████████| 95/95 [00:01<00:00, 52.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario1 route0 completed ...\n",
      "100%|██████████| 1/1 [00:00<00:00, 26.86it/s]\n",
      "There are 92 samples in Demo dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [07:10<00:00,  9.35s/it]\n",
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|██████████| 92/92 [00:01<00:00, 52.34it/s]\n",
      "100%|██████████| 92/92 [00:01<00:00, 52.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario1 route2 completed ...\n",
      "100%|██████████| 1/1 [00:00<00:00, 28.46it/s]\n",
      "There are 86 samples in Demo dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [07:02<00:00,  9.84s/it]\n",
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|██████████| 86/86 [00:01<00:00, 47.44it/s]\n",
      "100%|██████████| 86/86 [00:01<00:00, 47.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario1 route3 completed ...\n",
      "100%|██████████| 1/1 [00:00<00:00, 31.89it/s]\n",
      "There are 93 samples in Demo dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [08:05<00:00, 10.32s/it]\n",
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|██████████| 93/93 [00:01<00:00, 53.34it/s]\n",
      "100%|██████████| 93/93 [00:01<00:00, 53.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario3 route0 completed ...\n",
      "100%|██████████| 1/1 [00:00<00:00, 20.61it/s]\n",
      "There are 97 samples in Demo dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [08:35<00:00, 10.51s/it]\n",
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|██████████| 97/97 [00:01<00:00, 52.89it/s]\n",
      "100%|██████████| 97/97 [00:01<00:00, 52.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario3 route1 completed ...\n",
      "100%|██████████| 1/1 [00:00<00:00, 15.96it/s]\n",
      "There are 95 samples in Demo dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [08:43<00:00, 10.91s/it]\n",
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|██████████| 95/95 [00:01<00:00, 51.76it/s]\n",
      "100%|██████████| 95/95 [00:01<00:00, 51.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario3 route2 completed ...\n",
      "100%|██████████| 1/1 [00:00<00:00, 17.70it/s]\n",
      "There are 86 samples in Demo dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [07:51<00:00, 10.96s/it]\n",
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|██████████| 86/86 [00:02<00:00, 38.90it/s]\n",
      "100%|██████████| 86/86 [00:02<00:00, 38.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario7 route0 completed ...\n",
      "100%|██████████| 1/1 [00:00<00:00, 11.83it/s]\n",
      "There are 151 samples in Demo dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [14:13<00:00, 11.22s/it]\n",
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|██████████| 151/151 [00:02<00:00, 54.69it/s]\n",
      "100%|██████████| 151/151 [00:02<00:00, 54.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario7 route1 completed ...\n",
      "100%|██████████| 1/1 [00:00<00:00, 11.03it/s]\n",
      "There are 214 samples in Demo dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [20:56<00:00, 11.74s/it]\n",
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|██████████| 214/214 [00:05<00:00, 37.42it/s]\n",
      "100%|██████████| 214/214 [00:05<00:00, 37.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario7 route2 completed ...\n",
      "100%|██████████| 1/1 [00:00<00:00, 11.97it/s]\n",
      "There are 87 samples in Demo dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [08:41<00:00, 11.86s/it]\n",
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|██████████| 87/87 [00:01<00:00, 54.28it/s]\n",
      "100%|██████████| 87/87 [00:01<00:00, 54.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario8 route0 completed ...\n",
      "100%|██████████| 1/1 [00:00<00:00, 20.20it/s]\n",
      "There are 99 samples in Demo dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:26<00:00, 12.52s/it]\n",
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|██████████| 99/99 [00:01<00:00, 54.37it/s]\n",
      "100%|██████████| 99/99 [00:01<00:00, 54.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario8 route1 completed ...\n",
      "100%|██████████| 1/1 [00:00<00:00, 20.49it/s]\n",
      "There are 118 samples in Demo dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [12:03<00:00, 12.27s/it]\n",
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|██████████| 118/118 [00:03<00:00, 32.57it/s]\n",
      "100%|██████████| 118/118 [00:03<00:00, 32.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario8 route2 completed ...\n",
      "100%|██████████| 1/1 [00:00<00:00, 38.31it/s]\n",
      "There are 44 samples in Demo dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [04:38<00:00, 12.67s/it]\n",
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|██████████| 44/44 [00:01<00:00, 33.40it/s]\n",
      "100%|██████████| 44/44 [00:01<00:00, 33.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario9 route0 completed ...\n",
      "100%|██████████| 1/1 [00:00<00:00, 40.83it/s]\n",
      "There are 42 samples in Demo dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [04:36<00:00, 13.16s/it]\n",
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|██████████| 42/42 [00:01<00:00, 30.00it/s]\n",
      "100%|██████████| 42/42 [00:01<00:00, 29.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario9 route1 completed ...\n",
      "100%|██████████| 1/1 [00:00<00:00, 35.09it/s]\n",
      "There are 41 samples in Demo dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [04:33<00:00, 13.04s/it]\n",
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|██████████| 41/41 [00:00<00:00, 53.07it/s]\n",
      "100%|██████████| 41/41 [00:00<00:00, 52.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario9 route2 completed ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib agg\n",
    "visualizer = Visualizer(model_name='TRANSFUSER')\n",
    "\n",
    "root_dir = '/kaggle/input/carla-e2e-data/demo/'\n",
    "scenarios = sorted(os.listdir(root_dir))\n",
    "for scenario in scenarios:\n",
    "    scenario_dir = os.path.join(root_dir, scenario)\n",
    "    routes = sorted(os.listdir(scenario_dir))\n",
    "    \n",
    "    for route in routes:\n",
    "        route_name = get_route_name(route)\n",
    "        route_dir = os.path.join(scenario_dir, route)\n",
    "        demo_set = CARLA_Data(root=scenario_dir, config=config, routeKey=route_name, load_raw_lidar=True)\n",
    "        print(f\"There are {len(demo_set)} samples in Demo dataset\")\n",
    "        dataloader_demo = DataLoader(demo_set, shuffle=False, batch_size=2, num_workers=4)\n",
    "        \n",
    "        # create output directory for scenario\n",
    "        output_dir = os.path.join(os.getcwd(), *[scenario, route_name])\n",
    "        os.makedirs(output_dir, exist_ok = True)\n",
    "        \n",
    "        write_model_predictions(dataloader_demo, output_dir)\n",
    "        convert_images_to_video(output_dir, f'{scenario}_{route_name}_{model.pred_len}pts_{FPS}fps.mp4', fps=FPS)\n",
    "        print(f\"{scenario} {route_name} completed ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185fc0d6",
   "metadata": {
    "papermill": {
     "duration": 0.113019,
     "end_time": "2024-07-28T13:20:43.136727",
     "exception": false,
     "start_time": "2024-07-28T13:20:43.023708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4849257,
     "sourceId": 8287109,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4922400,
     "sourceId": 8287377,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4849261,
     "sourceId": 9051268,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8260.401973,
   "end_time": "2024-07-28T13:20:45.986453",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-28T11:03:05.584480",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0603468804ba4fdab4cfb8bca81ab58f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_21aae112b68f4bfabfc5d987a3cc1ea2",
        "IPY_MODEL_ec61c809603e450d9990366247f1329c",
        "IPY_MODEL_58a569a8ce8d4e00bd76970b41786746"
       ],
       "layout": "IPY_MODEL_bda03f1e4e3d469b9cf2ca04f0f4bf37"
      }
     },
     "07b22634a3854e7b999bb678039fb26e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "157168b0ec7646da9746659b15a45619": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "21aae112b68f4bfabfc5d987a3cc1ea2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_07b22634a3854e7b999bb678039fb26e",
       "placeholder": "​",
       "style": "IPY_MODEL_7866ce8cdf084adfb41b872e60a1191b",
       "value": "model.safetensors: 100%"
      }
     },
     "35d0b3527c694b63a0542ef1e0698419": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "35d67aabbac2441ab73a10a9c12535c3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "58a569a8ce8d4e00bd76970b41786746": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b52cd71e7d4d4b9387d3e701c0f13a8d",
       "placeholder": "​",
       "style": "IPY_MODEL_35d0b3527c694b63a0542ef1e0698419",
       "value": " 78.1M/78.1M [00:01&lt;00:00, 62.4MB/s]"
      }
     },
     "7866ce8cdf084adfb41b872e60a1191b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b52cd71e7d4d4b9387d3e701c0f13a8d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bda03f1e4e3d469b9cf2ca04f0f4bf37": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ec61c809603e450d9990366247f1329c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_157168b0ec7646da9746659b15a45619",
       "max": 78055620.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_35d67aabbac2441ab73a10a9c12535c3",
       "value": 78055620.0
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
