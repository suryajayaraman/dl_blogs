{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# torch imports\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CARLA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:01<00:00,  8.98it/s]\n",
      "Loading 16088 lidars from 11 folders\n",
      "100%|██████████| 8/8 [00:00<00:00,  9.93it/s]\n",
      "Loading 11543 lidars from 8 folders\n",
      "There are 16088 samples in training set\n"
     ]
    }
   ],
   "source": [
    "from config import GlobalConfig\n",
    "from data import CARLA_Data\n",
    "\n",
    "root_dir = '/home/surya/Downloads/transfuser-2022/data/'\n",
    "config = GlobalConfig(root_dir=root_dir, setting='all')\n",
    "train_set = CARLA_Data(root=config.train_data, config=config)\n",
    "val_set = CARLA_Data(root=config.val_data, config=config)\n",
    "print(f\"There are {len(train_set)} samples in training set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pytorch style dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "g_cuda = torch.Generator(device='cpu')\n",
    "g_cuda.manual_seed(torch.initial_seed())\n",
    "\n",
    "# We need to seed the workers individually otherwise random processes \n",
    "# in the dataloader return the same values across workers!\n",
    "def seed_worker(worker_id):\n",
    "    # Torch initial seed is properly set across the different workers,\n",
    "    # we need to pass it to numpy and random.\n",
    "    worker_seed = (torch.initial_seed()) % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "dataloader_train = DataLoader(train_set, shuffle=True, batch_size=2, worker_init_fn=seed_worker, generator=g_cuda, num_workers=4)\n",
    "dataloader_valid   = DataLoader(val_set, shuffle=False, batch_size=2, worker_init_fn=seed_worker, generator=g_cuda, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample data is of type <class 'dict'> and has following keys\n",
      "rgb [2, 3, 160, 704]\n",
      "bev [2, 160, 160]\n",
      "depth [2, 160, 704]\n",
      "semantic [2, 160, 704]\n",
      "steer [2]\n",
      "throttle [2]\n",
      "brake [2]\n",
      "speed [2]\n",
      "theta [2]\n",
      "x_command [2]\n",
      "y_command [2]\n",
      "light [2]\n",
      "target_point [2, 2]\n",
      "target_point_image [2, 1, 256, 256]\n",
      "lidar [2, 2, 256, 256]\n",
      "label [2, 20, 7]\n",
      "ego_waypoint [2, 4, 2]\n"
     ]
    }
   ],
   "source": [
    "sample_data = next(iter(dataloader_train))\n",
    "print(f\"sample data is of type {type(sample_data)} and has following keys\")\n",
    "\n",
    "for k,v in sample_data.items():\n",
    "    print(k, list(v.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_model(model, num_epochs, model_name, optimizer, \n",
    "                         device, dataloader_train, dataloader_valid, \n",
    "                         lr_scheduler = None, output_path = '.'):\n",
    "\n",
    "    # initialize placeholders for running values\n",
    "    train_results = []    \n",
    "    val_results = []    \n",
    "    min_val_loss = np.Inf\n",
    "\n",
    "    # move model to device\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        epoch_detailed_train_losses  = {key: 0.0 for key in config.detailed_losses}\n",
    "        epoch_detailed_train_losses['weighted_loss'] = 0.0\n",
    "        \n",
    "        with tqdm(dataloader_train, unit=\"batch\") as tepoch:\n",
    "            for batch_idx, data in enumerate(tepoch):\n",
    "                tepoch.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "                # load data to gpu, according to type\n",
    "                for k in ['rgb', 'depth', 'lidar', 'label', 'ego_waypoint', \\\n",
    "                          'target_point', 'target_point_image', 'speed']:\n",
    "                    data[k] = data[k].to(device, torch.float32)\n",
    "                for k in ['semantic', 'bev']:\n",
    "                    data[k] = data[k].to(device, torch.long)\n",
    "                \n",
    "                # forward pass, store losses\n",
    "                losses = model(data)\n",
    "                loss = torch.tensor(0.0).to(device, dtype=torch.float32)\n",
    "                for key, value in losses.items():\n",
    "                    loss += detailed_weights[key] * value\n",
    "                    epoch_detailed_train_losses[key] += float(detailed_weights[key] * value.item())\n",
    "                epoch_detailed_train_losses['weighted_loss'] += float(loss.item())\n",
    "                \n",
    "                # backward pass\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # log losses\n",
    "                tepoch.set_postfix(loss=loss.item())\n",
    "\n",
    "                if batch_idx == 2:\n",
    "                    break\n",
    "            \n",
    "            # average losses across batches\n",
    "            for k,v in epoch_detailed_train_losses.items():\n",
    "                epoch_detailed_train_losses[k] = v / len(dataloader_train)\n",
    "            \n",
    "#         validation_loss, validation_metric = evaluate_model(\n",
    "#                         model, dataloader_valid, criterion, metric_class, num_classes, device)\n",
    "\n",
    "        \n",
    "        train_results.append(epoch_detailed_train_losses)\n",
    "    \n",
    "    return train_results, val_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters:  168018327\n"
     ]
    }
   ],
   "source": [
    "from model import LidarCenterNet\n",
    "model = LidarCenterNet(config, device, config.backbone, image_architecture='regnety_032', \n",
    "                           lidar_architecture='regnety_032', use_velocity=False)\n",
    "model.to(device);\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print ('Total trainable parameters: ', params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 1\n",
    "\n",
    "detailed_weights = {key: config.detailed_losses_weights[idx] for idx, key in enumerate(config.detailed_losses)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 2/8044 [00:16<18:37:29,  8.34s/batch, loss=302] \n"
     ]
    }
   ],
   "source": [
    "train_results, val_results = train_validate_model(model, num_epochs=N_EPOCHS, model_name='Transfuser_regnet032', \n",
    "                                                  optimizer=optimizer,device = device, dataloader_train=dataloader_train, \n",
    "                                                  dataloader_valid = dataloader_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss_wp': 0.0006791537137603002,\n",
       "  'loss_bev': 0.00040492759244113583,\n",
       "  'loss_depth': 0.0017792778427715861,\n",
       "  'loss_semantic': 0.0007342136303386186,\n",
       "  'loss_center_heatmap': 0.06452217045143314,\n",
       "  'loss_wh': 4.535051852775889e-05,\n",
       "  'loss_offset': 2.235929462697481e-05,\n",
       "  'loss_yaw_class': 0.0003740036683198767,\n",
       "  'loss_yaw_res': 1.0020414951985308e-08,\n",
       "  'loss_velocity': 0.0,\n",
       "  'loss_brake': 0.0,\n",
       "  'weighted_loss': 0.06856146669696066}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_wp</th>\n",
       "      <th>loss_bev</th>\n",
       "      <th>loss_depth</th>\n",
       "      <th>loss_semantic</th>\n",
       "      <th>loss_center_heatmap</th>\n",
       "      <th>loss_wh</th>\n",
       "      <th>loss_offset</th>\n",
       "      <th>loss_yaw_class</th>\n",
       "      <th>loss_yaw_res</th>\n",
       "      <th>loss_velocity</th>\n",
       "      <th>loss_brake</th>\n",
       "      <th>weighted_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.064522</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>1.002041e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    loss_wp  loss_bev  loss_depth  loss_semantic  loss_center_heatmap  \\\n",
       "0  0.000679  0.000405    0.001779       0.000734             0.064522   \n",
       "\n",
       "    loss_wh  loss_offset  loss_yaw_class  loss_yaw_res  loss_velocity  \\\n",
       "0  0.000045     0.000022        0.000374  1.002041e-08            0.0   \n",
       "\n",
       "   loss_brake  weighted_loss  \n",
       "0         0.0       0.068561  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_results = pd.DataFrame(train_results)\n",
    "train_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
